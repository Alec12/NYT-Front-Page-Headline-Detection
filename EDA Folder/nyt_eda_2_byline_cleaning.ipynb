{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing work done in nyt_eda.ipynb\n",
    "- extract byline information\n",
    "- do sanity check to ensure that Author matches person or organization in byline dictionary in most/all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import re\n",
    "\n",
    "\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scj41343\\AppData\\Local\\Temp\\ipykernel_6660\\1158527711.py:3: DtypeWarning: Columns (5,23,24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  rest = pd.read_csv('rest.zip', compression='zip', sep=',')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392847, 31)\n",
      "(21917, 27)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "#front_pages=pd.read_csv('front_pages.zip',compression='zip', sep=',') \n",
    "rest = pd.read_csv('rest.zip', compression='zip', sep=',')\n",
    "print(rest.shape)\n",
    "\n",
    "with gzip.open('frontpages.zip', 'rb') as f:\n",
    "    front_pages = pd.read_csv(f)\n",
    "print(front_pages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abstract            1021\n",
       "weburl                 1\n",
       "snippet             6522\n",
       "leadparagraph       4353\n",
       "printsection      209304\n",
       "printpage         209294\n",
       "source                 1\n",
       "multimedia             1\n",
       "headline               1\n",
       "keywords               1\n",
       "pubdate                1\n",
       "documenttype           1\n",
       "newsdesk           12665\n",
       "sectionname          328\n",
       "subsectionname    239421\n",
       "byline                 1\n",
       "typeofmaterial      7590\n",
       "id                     1\n",
       "wordcount              1\n",
       "uri                    1\n",
       "year                   1\n",
       "numsubjects            1\n",
       "numpersons             1\n",
       "numglocs               1\n",
       "numcreatives           1\n",
       "numorgs                1\n",
       "glocs                  1\n",
       "persons                1\n",
       "subjects               2\n",
       "orgs                   2\n",
       "cworks                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove underscore from column names as python was not liking them in byline_extraction function, not sure why\n",
    "rest.columns = rest.columns.str.replace(\"_\",\"\")\n",
    "front_pages.columns = front_pages.columns.str.replace(\"_\",\"\")\n",
    "#determine N/A counts for rest df\n",
    "rest.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abstract             0\n",
       "weburl               0\n",
       "snippet              2\n",
       "leadparagraph       66\n",
       "printsection         0\n",
       "printpage            0\n",
       "source               0\n",
       "multimedia           0\n",
       "headline             0\n",
       "keywords             0\n",
       "pubdate              0\n",
       "documenttype         0\n",
       "newsdesk            13\n",
       "sectionname          0\n",
       "subsectionname    8844\n",
       "byline               0\n",
       "typeofmaterial       0\n",
       "id                   0\n",
       "wordcount            0\n",
       "uri                  0\n",
       "year                 0\n",
       "numsubj              0\n",
       "numpersons           0\n",
       "numglocs             0\n",
       "numcreatives         0\n",
       "persons              0\n",
       "subjects             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#determine N/A counts for front pages df\n",
    "front_pages.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop one row where byline = 188 (int)\n",
    "intbyline = rest['byline'] == '188'\n",
    "rest = rest[~intbyline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392845, 31)\n",
      "Index(['abstract', 'weburl', 'snippet', 'leadparagraph', 'printsection',\n",
      "       'printpage', 'source', 'multimedia', 'headline', 'keywords', 'pubdate',\n",
      "       'documenttype', 'newsdesk', 'sectionname', 'subsectionname', 'byline',\n",
      "       'typeofmaterial', 'id', 'wordcount', 'uri', 'year', 'numsubjects',\n",
      "       'numpersons', 'numglocs', 'numcreatives', 'numorgs', 'glocs', 'persons',\n",
      "       'subjects', 'orgs', 'cworks'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#drop rows with N/As\n",
    "rest = rest[rest['byline'].notna()]\n",
    "#reset index so df is clean still\n",
    "rest = rest.reset_index(drop=True)\n",
    "print(rest.shape)\n",
    "print(rest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21917, 27)\n",
      "Index(['abstract', 'weburl', 'snippet', 'leadparagraph', 'printsection',\n",
      "       'printpage', 'source', 'multimedia', 'headline', 'keywords', 'pubdate',\n",
      "       'documenttype', 'newsdesk', 'sectionname', 'subsectionname', 'byline',\n",
      "       'typeofmaterial', 'id', 'wordcount', 'uri', 'year', 'numsubj',\n",
      "       'numpersons', 'numglocs', 'numcreatives', 'persons', 'subjects'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#drop rows with N/As (this was done before the N/A count for front pages was done, so it was learned that it was not necessary)\n",
    "front_pages = front_pages[front_pages['byline'].notna()]\n",
    "#reset index so df is clean still\n",
    "front_pages = front_pages.reset_index(drop=True)\n",
    "print(front_pages.shape)\n",
    "print(front_pages.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byline_extraction(df):\n",
    "    #initialize empty columns to store extracted strings\n",
    "    df['byline_extract'] = \"\"\n",
    "    df['byline_confirm'] = \"\"\n",
    "    df['byline_match'] = \"\"\n",
    "\n",
    "    #for every row in the provided dataframe, turn string into dictionary\n",
    "    #the author is extracted from the value of the original key, remove additional text to just get the name of the person or organization\n",
    "    #only assign first author, so remove anything after 'and' or ','\n",
    "    for row in range(0,df.shape[0]):\n",
    "        dict = literal_eval(df['byline'].loc[row])\n",
    "        author = dict['original']\n",
    "        author = re.sub('By ','',author)\n",
    "        author = re.sub(' By ','',author)\n",
    "        author = re.sub('text by ','',author,flags=re.I)\n",
    "        author = re.sub('interview by ','',author,flags=re.I)\n",
    "        author = re.sub('compiled by ','',author,flags=re.I)\n",
    "        author = re.sub('photographs by ','',author,flags=re.I)\n",
    "        author = re.sub('text and photographs by ','',author,flags=re.I)\n",
    "        if ' and' in author:\n",
    "            author = author[:author.index(' and')]\n",
    "        if ', ' in author:\n",
    "            author = author[:author.index(', ')]\n",
    "        #capitalize name correctly and remove and whitespace\n",
    "        author = author.title()\n",
    "        author = author.strip()\n",
    "        #assign the byline_extract with the author\n",
    "        df.loc[row,'byline_extract'] = author\n",
    "        \n",
    "        #if the person dictionary is empty, this indicates it is an organization as the author, use organization dict to confirm\n",
    "        if dict['person'] == []:\n",
    "            author_con = dict['organization']\n",
    "            if not author_con:\n",
    "                #if there is no organization dictionary, assign N/A to byline_confirm\n",
    "                author_con = 'N/A'\n",
    "            author_confirm = author_con\n",
    "        else:\n",
    "            author_con = dict['person']\n",
    "            #get the byline information from the person dictionary in order to confirm that they match\n",
    "            #if there is no person dictionary, assign N/A to byline_confirm\n",
    "            if not author_con:\n",
    "                author_con = 'N/A'\n",
    "            else:\n",
    "                #if there is a person dictionary, extract the first and last name, if there is a middle name, extract that as well\n",
    "                #concatenate the first, possible middle, and last names (and qualifiers if needed ex: Jr)\n",
    "                author_con = author_con[0]\n",
    "                author_first = author_con['firstname']\n",
    "                author_last = author_con['lastname']\n",
    "                if author_con['middlename'] != None:\n",
    "                    author_middle = author_con['middlename']\n",
    "                    author_confirm = author_first + \" \" + author_middle + \" \" + author_last\n",
    "                else:\n",
    "                    author_confirm = author_first + \" \" + author_last\n",
    "                if author_con['qualifier'] != None:\n",
    "                    author_qual = author_con['qualifier']\n",
    "                    author_confirm = author_confirm + \" \" + author_qual\n",
    "            #remove additional works just to get the author\n",
    "            author_confirm = re.sub('text ','',author_confirm,flags=re.I)\n",
    "            author_confirm = re.sub('interview ','',author_confirm,flags=re.I)\n",
    "            author_confirm = re.sub('photograph ','',author_confirm,flags=re.I)\n",
    "            author_confirm = author_confirm.replace('M.D','')\n",
    "        #capitalize name correctly and remove and whitespace\n",
    "        author_confirm = author_confirm.title()\n",
    "        author_confirm = author_confirm.strip()\n",
    "        #assign name to byline_confirm\n",
    "        df.loc[row,'byline_confirm'] = author_confirm\n",
    "        \n",
    "        #check to see if byline_extract and byline_confirm match\n",
    "        if author == author_confirm:\n",
    "            df.loc[row,'byline_match'] = \"Yes\"\n",
    "        else:\n",
    "            df.loc[row,'byline_match'] = \"No\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest = byline_extraction(rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_pages = byline_extraction(front_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21058\n",
      "859\n"
     ]
    }
   ],
   "source": [
    "print(front_pages['byline_match'].value_counts()['Yes'])\n",
    "print(front_pages['byline_match'].value_counts()['No'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpissues = front_pages[front_pages['byline_match'] == 'No']\n",
    "fpissues = fpissues[['byline','byline_extract','byline_confirm']]\n",
    "fpissues = fpissues.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpissues.to_csv('fpissues.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346336\n",
      "46509\n"
     ]
    }
   ],
   "source": [
    "print(rest['byline_match'].value_counts()['Yes'])\n",
    "print(rest['byline_match'].value_counts()['No'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rissues = rest[rest['byline_match'] == 'No']\n",
    "rissues = rissues[['byline','byline_extract','byline_confirm']]\n",
    "rissues = rissues.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rissues.to_csv('rissues.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest.to_csv('rest_byline_cleaned.gz',compression = 'gzip')\n",
    "front_pages.to_csv('front_pages_byline_cleaned.gz', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest.to_csv('rest_byline_cleaned.csv')\n",
    "front_pages.to_csv('front_pages_byline_cleaned.csv',)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
